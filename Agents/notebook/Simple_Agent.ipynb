{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b11fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931ca49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\"gpt-5\")\n",
    "\n",
    "#agent = create_agent(\"gpt-5\", tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0cec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain about AI Agents.\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cfae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain about AI Agents.', additional_kwargs={}, response_metadata={}, id='6e38d66c-ab6b-4a29-bc30-fb017588a26f'),\n",
       "  AIMessage(content='AI agents: a concise overview\\n\\nWhat they are\\n- An AI agent is a system that perceives its environment, decides what to do, and acts to achieve goals autonomously. Unlike a simple program or chatbot that only answers prompts, an agent maintains state, can plan over multiple steps, use tools, and adapt its behavior based on feedback.\\n\\nCore loop\\n- Sense: gather observations (user input, web/data APIs, sensors).\\n- Think: update internal state, reason/plan, choose an action.\\n- Act: call tools/APIs, take real-world actions, or reply.\\n- Learn: update models, memories, or policies from outcomes.\\n\\nKey components\\n- Perception: parsers, extractors, retrieval (RAG), sensors.\\n- State/memory: short-term scratchpad; longer-term episodic/semantic memory (often vector stores).\\n- Policy/reasoner: rules, planners, learned policies, or LLMs.\\n- Tools/actuators: function calls, databases, web browsers, code interpreters, robots.\\n- Planner/executor: breaks goals into steps; monitors progress; handles errors and retries.\\n- Critic/guardrails: validators, safety checks, permissioning.\\n- Reward/feedback: metrics or rewards for learning or self-correction.\\n\\nAgent types (classic to modern)\\n- Reactive: map observations directly to actions; fast, no internal model.\\n- Model-based: maintain an internal state/world model to plan.\\n- Goal/utility-based: select actions to maximize goal attainment or utility.\\n- Learning agents: improve over time via supervised, RL, or self-play.\\n- LLM-based agents: use a large language model as the “brain” for planning, tool use, and dialogue; often follow patterns like ReAct (reason + act), tool calling, and planning/critique loops.\\n- Multi-agent systems: multiple specialized agents coordinating or competing to solve complex tasks.\\n\\nCommon patterns in LLM agents\\n- Tool use: the model decides when to call functions/APIs (search, DB query, code exec).\\n- Retrieval-augmented generation: fetch relevant knowledge to ground responses.\\n- Planning and execution: decompose tasks, schedule steps, track state.\\n- Reflection/critique: review outputs, detect errors, retry with improvements.\\n- Memory: store facts, preferences, and past interactions to personalize and improve.\\n\\nUse cases\\n- Productivity: personal assistants, meeting copilots, email/calendar automation.\\n- Data/knowledge work: research, analytics, report generation, BI queries.\\n- Software: coding agents (issue triage, PRs), test generation, CI/CD ops.\\n- Operations: workflow automation across SaaS, RPA-like actions.\\n- Web agents: browsing, form-filling, procurement, competitive intel.\\n- Finance/trading: monitoring, signal extraction, execution (with strict controls).\\n- Customer support: triage, resolution with tool access and knowledge bases.\\n- Robotics/IoT: navigation, manipulation, process control.\\n\\nHow they differ from chatbots and workflows\\n- Chatbots: primarily single-turn or short multi-turn text responses; no or minimal tool use/state.\\n- Workflows/RPA: fixed sequences; brittle to change.\\n- Agents: goal-directed, stateful, can plan, choose tools, and adapt to changing conditions.\\n\\nBuilding one (practical steps)\\n- Define the goal, environment, and allowed actions/tools; restrict permissions.\\n- Choose the core reasoner: rules, planner, RL policy, or an LLM.\\n- Add perception and retrieval to ground decisions.\\n- Implement a planner/executor with error handling and retries.\\n- Add memory appropriately (start simple; avoid uncontrolled growth).\\n- Wrap tools with schemas, validation, and sandboxing.\\n- Log everything; add metrics, tracing, and evaluation harnesses.\\n- Start with a narrow scope; iterate with real tasks and feedback.\\n\\nEcosystem and frameworks (examples)\\n- Orchestration: LangChain/LangGraph, Microsoft Semantic Kernel, AutoGen, CrewAI.\\n- Tool-calling: function/tool APIs from major LLM providers; JSON schema validation.\\n- Memory/RAG: vector databases (FAISS, Chroma, Pinecone, Weaviate), text chunkers, retrievers.\\n- Evaluation: task suites like SWE-bench (coding), WebArena/AgentBench (web), GAIA (general grounded QA).\\n\\nChallenges and risks\\n- Reliability: long-horizon planning, tool selection, and error recovery are brittle.\\n- Hallucinations and grounding: use retrieval, tool checks, and validators.\\n- Cost/latency: frequent tool calls and planning loops can be expensive/slow; cache and batch.\\n- Safety/security: prompt injection, data exfiltration, insecure tool use; enforce least privilege, input/output filters, sandboxing, rate limits, and secret isolation.\\n- Oversight: define explicit success criteria; require human-in-the-loop for high-stakes actions.\\n- Evaluation: measure task success, cumulative reward, time-to-completion, robustness, cost.\\n\\nGood practices\\n- Constrain the action space; make tools explicit and typed.\\n- Add pre/post-conditions and schema validators for tool I/O.\\n- Use retrieval and deterministic tools to ground answers.\\n- Implement retries with backoff and critique, not infinite loops.\\n- Instrument with tracing, event logs, and cost tracking.\\n- Start with non-destructive read-only modes; graduate to write actions with approvals.\\n- Regularly red-team against prompt injection and jailbreaks.\\n\\nIn short: AI agents are autonomous, goal-driven systems that perceive, decide, and act. Modern agents often use LLMs to plan and operate tools, augmented with memory, retrieval, and guardrails. The hard parts are reliability, safety, and evaluation—scope tightly, measure, and iterate.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2077, 'prompt_tokens': 11, 'total_tokens': 2088, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtT9ipgmzd7ieMqryCQcZBPif1JHO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b7d71-82b7-7fd0-974d-a6d521159c37-0', usage_metadata={'input_tokens': 11, 'output_tokens': 2077, 'total_tokens': 2088, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa7e335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_content = result[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f524f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Explain about AI Agents.', additional_kwargs={}, response_metadata={}, id='6e38d66c-ab6b-4a29-bc30-fb017588a26f'),\n",
       " AIMessage(content='AI agents: a concise overview\\n\\nWhat they are\\n- An AI agent is a system that perceives its environment, decides what to do, and acts to achieve goals autonomously. Unlike a simple program or chatbot that only answers prompts, an agent maintains state, can plan over multiple steps, use tools, and adapt its behavior based on feedback.\\n\\nCore loop\\n- Sense: gather observations (user input, web/data APIs, sensors).\\n- Think: update internal state, reason/plan, choose an action.\\n- Act: call tools/APIs, take real-world actions, or reply.\\n- Learn: update models, memories, or policies from outcomes.\\n\\nKey components\\n- Perception: parsers, extractors, retrieval (RAG), sensors.\\n- State/memory: short-term scratchpad; longer-term episodic/semantic memory (often vector stores).\\n- Policy/reasoner: rules, planners, learned policies, or LLMs.\\n- Tools/actuators: function calls, databases, web browsers, code interpreters, robots.\\n- Planner/executor: breaks goals into steps; monitors progress; handles errors and retries.\\n- Critic/guardrails: validators, safety checks, permissioning.\\n- Reward/feedback: metrics or rewards for learning or self-correction.\\n\\nAgent types (classic to modern)\\n- Reactive: map observations directly to actions; fast, no internal model.\\n- Model-based: maintain an internal state/world model to plan.\\n- Goal/utility-based: select actions to maximize goal attainment or utility.\\n- Learning agents: improve over time via supervised, RL, or self-play.\\n- LLM-based agents: use a large language model as the “brain” for planning, tool use, and dialogue; often follow patterns like ReAct (reason + act), tool calling, and planning/critique loops.\\n- Multi-agent systems: multiple specialized agents coordinating or competing to solve complex tasks.\\n\\nCommon patterns in LLM agents\\n- Tool use: the model decides when to call functions/APIs (search, DB query, code exec).\\n- Retrieval-augmented generation: fetch relevant knowledge to ground responses.\\n- Planning and execution: decompose tasks, schedule steps, track state.\\n- Reflection/critique: review outputs, detect errors, retry with improvements.\\n- Memory: store facts, preferences, and past interactions to personalize and improve.\\n\\nUse cases\\n- Productivity: personal assistants, meeting copilots, email/calendar automation.\\n- Data/knowledge work: research, analytics, report generation, BI queries.\\n- Software: coding agents (issue triage, PRs), test generation, CI/CD ops.\\n- Operations: workflow automation across SaaS, RPA-like actions.\\n- Web agents: browsing, form-filling, procurement, competitive intel.\\n- Finance/trading: monitoring, signal extraction, execution (with strict controls).\\n- Customer support: triage, resolution with tool access and knowledge bases.\\n- Robotics/IoT: navigation, manipulation, process control.\\n\\nHow they differ from chatbots and workflows\\n- Chatbots: primarily single-turn or short multi-turn text responses; no or minimal tool use/state.\\n- Workflows/RPA: fixed sequences; brittle to change.\\n- Agents: goal-directed, stateful, can plan, choose tools, and adapt to changing conditions.\\n\\nBuilding one (practical steps)\\n- Define the goal, environment, and allowed actions/tools; restrict permissions.\\n- Choose the core reasoner: rules, planner, RL policy, or an LLM.\\n- Add perception and retrieval to ground decisions.\\n- Implement a planner/executor with error handling and retries.\\n- Add memory appropriately (start simple; avoid uncontrolled growth).\\n- Wrap tools with schemas, validation, and sandboxing.\\n- Log everything; add metrics, tracing, and evaluation harnesses.\\n- Start with a narrow scope; iterate with real tasks and feedback.\\n\\nEcosystem and frameworks (examples)\\n- Orchestration: LangChain/LangGraph, Microsoft Semantic Kernel, AutoGen, CrewAI.\\n- Tool-calling: function/tool APIs from major LLM providers; JSON schema validation.\\n- Memory/RAG: vector databases (FAISS, Chroma, Pinecone, Weaviate), text chunkers, retrievers.\\n- Evaluation: task suites like SWE-bench (coding), WebArena/AgentBench (web), GAIA (general grounded QA).\\n\\nChallenges and risks\\n- Reliability: long-horizon planning, tool selection, and error recovery are brittle.\\n- Hallucinations and grounding: use retrieval, tool checks, and validators.\\n- Cost/latency: frequent tool calls and planning loops can be expensive/slow; cache and batch.\\n- Safety/security: prompt injection, data exfiltration, insecure tool use; enforce least privilege, input/output filters, sandboxing, rate limits, and secret isolation.\\n- Oversight: define explicit success criteria; require human-in-the-loop for high-stakes actions.\\n- Evaluation: measure task success, cumulative reward, time-to-completion, robustness, cost.\\n\\nGood practices\\n- Constrain the action space; make tools explicit and typed.\\n- Add pre/post-conditions and schema validators for tool I/O.\\n- Use retrieval and deterministic tools to ground answers.\\n- Implement retries with backoff and critique, not infinite loops.\\n- Instrument with tracing, event logs, and cost tracking.\\n- Start with non-destructive read-only modes; graduate to write actions with approvals.\\n- Regularly red-team against prompt injection and jailbreaks.\\n\\nIn short: AI agents are autonomous, goal-driven systems that perceive, decide, and act. Modern agents often use LLMs to plan and operate tools, augmented with memory, retrieval, and guardrails. The hard parts are reliability, safety, and evaluation—scope tightly, measure, and iterate.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2077, 'prompt_tokens': 11, 'total_tokens': 2088, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtT9ipgmzd7ieMqryCQcZBPif1JHO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b7d71-82b7-7fd0-974d-a6d521159c37-0', usage_metadata={'input_tokens': 11, 'output_tokens': 2077, 'total_tokens': 2088, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd6642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c31036f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='Explain about AI Agents.', additional_kwargs={}, response_metadata={}, id='6e38d66c-ab6b-4a29-bc30-fb017588a26f')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69acde87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain about AI Agents.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62bc940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI agents: a concise overview\\n\\nWhat they are\\n- An AI agent is a system that perceives its environment, decides what to do, and acts to achieve goals autonomously. Unlike a simple program or chatbot that only answers prompts, an agent maintains state, can plan over multiple steps, use tools, and adapt its behavior based on feedback.\\n\\nCore loop\\n- Sense: gather observations (user input, web/data APIs, sensors).\\n- Think: update internal state, reason/plan, choose an action.\\n- Act: call tools/APIs, take real-world actions, or reply.\\n- Learn: update models, memories, or policies from outcomes.\\n\\nKey components\\n- Perception: parsers, extractors, retrieval (RAG), sensors.\\n- State/memory: short-term scratchpad; longer-term episodic/semantic memory (often vector stores).\\n- Policy/reasoner: rules, planners, learned policies, or LLMs.\\n- Tools/actuators: function calls, databases, web browsers, code interpreters, robots.\\n- Planner/executor: breaks goals into steps; monitors progress; handles errors and retries.\\n- Critic/guardrails: validators, safety checks, permissioning.\\n- Reward/feedback: metrics or rewards for learning or self-correction.\\n\\nAgent types (classic to modern)\\n- Reactive: map observations directly to actions; fast, no internal model.\\n- Model-based: maintain an internal state/world model to plan.\\n- Goal/utility-based: select actions to maximize goal attainment or utility.\\n- Learning agents: improve over time via supervised, RL, or self-play.\\n- LLM-based agents: use a large language model as the “brain” for planning, tool use, and dialogue; often follow patterns like ReAct (reason + act), tool calling, and planning/critique loops.\\n- Multi-agent systems: multiple specialized agents coordinating or competing to solve complex tasks.\\n\\nCommon patterns in LLM agents\\n- Tool use: the model decides when to call functions/APIs (search, DB query, code exec).\\n- Retrieval-augmented generation: fetch relevant knowledge to ground responses.\\n- Planning and execution: decompose tasks, schedule steps, track state.\\n- Reflection/critique: review outputs, detect errors, retry with improvements.\\n- Memory: store facts, preferences, and past interactions to personalize and improve.\\n\\nUse cases\\n- Productivity: personal assistants, meeting copilots, email/calendar automation.\\n- Data/knowledge work: research, analytics, report generation, BI queries.\\n- Software: coding agents (issue triage, PRs), test generation, CI/CD ops.\\n- Operations: workflow automation across SaaS, RPA-like actions.\\n- Web agents: browsing, form-filling, procurement, competitive intel.\\n- Finance/trading: monitoring, signal extraction, execution (with strict controls).\\n- Customer support: triage, resolution with tool access and knowledge bases.\\n- Robotics/IoT: navigation, manipulation, process control.\\n\\nHow they differ from chatbots and workflows\\n- Chatbots: primarily single-turn or short multi-turn text responses; no or minimal tool use/state.\\n- Workflows/RPA: fixed sequences; brittle to change.\\n- Agents: goal-directed, stateful, can plan, choose tools, and adapt to changing conditions.\\n\\nBuilding one (practical steps)\\n- Define the goal, environment, and allowed actions/tools; restrict permissions.\\n- Choose the core reasoner: rules, planner, RL policy, or an LLM.\\n- Add perception and retrieval to ground decisions.\\n- Implement a planner/executor with error handling and retries.\\n- Add memory appropriately (start simple; avoid uncontrolled growth).\\n- Wrap tools with schemas, validation, and sandboxing.\\n- Log everything; add metrics, tracing, and evaluation harnesses.\\n- Start with a narrow scope; iterate with real tasks and feedback.\\n\\nEcosystem and frameworks (examples)\\n- Orchestration: LangChain/LangGraph, Microsoft Semantic Kernel, AutoGen, CrewAI.\\n- Tool-calling: function/tool APIs from major LLM providers; JSON schema validation.\\n- Memory/RAG: vector databases (FAISS, Chroma, Pinecone, Weaviate), text chunkers, retrievers.\\n- Evaluation: task suites like SWE-bench (coding), WebArena/AgentBench (web), GAIA (general grounded QA).\\n\\nChallenges and risks\\n- Reliability: long-horizon planning, tool selection, and error recovery are brittle.\\n- Hallucinations and grounding: use retrieval, tool checks, and validators.\\n- Cost/latency: frequent tool calls and planning loops can be expensive/slow; cache and batch.\\n- Safety/security: prompt injection, data exfiltration, insecure tool use; enforce least privilege, input/output filters, sandboxing, rate limits, and secret isolation.\\n- Oversight: define explicit success criteria; require human-in-the-loop for high-stakes actions.\\n- Evaluation: measure task success, cumulative reward, time-to-completion, robustness, cost.\\n\\nGood practices\\n- Constrain the action space; make tools explicit and typed.\\n- Add pre/post-conditions and schema validators for tool I/O.\\n- Use retrieval and deterministic tools to ground answers.\\n- Implement retries with backoff and critique, not infinite loops.\\n- Instrument with tracing, event logs, and cost tracking.\\n- Start with non-destructive read-only modes; graduate to write actions with approvals.\\n- Regularly red-team against prompt injection and jailbreaks.\\n\\nIn short: AI agents are autonomous, goal-driven systems that perceive, decide, and act. Modern agents often use LLMs to plan and operate tools, augmented with memory, retrieval, and guardrails. The hard parts are reliability, safety, and evaluation—scope tightly, measure, and iterate.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2077, 'prompt_tokens': 11, 'total_tokens': 2088, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CtT9ipgmzd7ieMqryCQcZBPif1JHO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b7d71-82b7-7fd0-974d-a6d521159c37-0', usage_metadata={'input_tokens': 11, 'output_tokens': 2077, 'total_tokens': 2088, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ea03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI agents: a concise overview\\n\\nWhat they are\\n- An AI agent is a system that perceives its environment, decides what to do, and acts to achieve goals autonomously. Unlike a simple program or chatbot that only answers prompts, an agent maintains state, can plan over multiple steps, use tools, and adapt its behavior based on feedback.\\n\\nCore loop\\n- Sense: gather observations (user input, web/data APIs, sensors).\\n- Think: update internal state, reason/plan, choose an action.\\n- Act: call tools/APIs, take real-world actions, or reply.\\n- Learn: update models, memories, or policies from outcomes.\\n\\nKey components\\n- Perception: parsers, extractors, retrieval (RAG), sensors.\\n- State/memory: short-term scratchpad; longer-term episodic/semantic memory (often vector stores).\\n- Policy/reasoner: rules, planners, learned policies, or LLMs.\\n- Tools/actuators: function calls, databases, web browsers, code interpreters, robots.\\n- Planner/executor: breaks goals into steps; monitors progress; handles errors and retries.\\n- Critic/guardrails: validators, safety checks, permissioning.\\n- Reward/feedback: metrics or rewards for learning or self-correction.\\n\\nAgent types (classic to modern)\\n- Reactive: map observations directly to actions; fast, no internal model.\\n- Model-based: maintain an internal state/world model to plan.\\n- Goal/utility-based: select actions to maximize goal attainment or utility.\\n- Learning agents: improve over time via supervised, RL, or self-play.\\n- LLM-based agents: use a large language model as the “brain” for planning, tool use, and dialogue; often follow patterns like ReAct (reason + act), tool calling, and planning/critique loops.\\n- Multi-agent systems: multiple specialized agents coordinating or competing to solve complex tasks.\\n\\nCommon patterns in LLM agents\\n- Tool use: the model decides when to call functions/APIs (search, DB query, code exec).\\n- Retrieval-augmented generation: fetch relevant knowledge to ground responses.\\n- Planning and execution: decompose tasks, schedule steps, track state.\\n- Reflection/critique: review outputs, detect errors, retry with improvements.\\n- Memory: store facts, preferences, and past interactions to personalize and improve.\\n\\nUse cases\\n- Productivity: personal assistants, meeting copilots, email/calendar automation.\\n- Data/knowledge work: research, analytics, report generation, BI queries.\\n- Software: coding agents (issue triage, PRs), test generation, CI/CD ops.\\n- Operations: workflow automation across SaaS, RPA-like actions.\\n- Web agents: browsing, form-filling, procurement, competitive intel.\\n- Finance/trading: monitoring, signal extraction, execution (with strict controls).\\n- Customer support: triage, resolution with tool access and knowledge bases.\\n- Robotics/IoT: navigation, manipulation, process control.\\n\\nHow they differ from chatbots and workflows\\n- Chatbots: primarily single-turn or short multi-turn text responses; no or minimal tool use/state.\\n- Workflows/RPA: fixed sequences; brittle to change.\\n- Agents: goal-directed, stateful, can plan, choose tools, and adapt to changing conditions.\\n\\nBuilding one (practical steps)\\n- Define the goal, environment, and allowed actions/tools; restrict permissions.\\n- Choose the core reasoner: rules, planner, RL policy, or an LLM.\\n- Add perception and retrieval to ground decisions.\\n- Implement a planner/executor with error handling and retries.\\n- Add memory appropriately (start simple; avoid uncontrolled growth).\\n- Wrap tools with schemas, validation, and sandboxing.\\n- Log everything; add metrics, tracing, and evaluation harnesses.\\n- Start with a narrow scope; iterate with real tasks and feedback.\\n\\nEcosystem and frameworks (examples)\\n- Orchestration: LangChain/LangGraph, Microsoft Semantic Kernel, AutoGen, CrewAI.\\n- Tool-calling: function/tool APIs from major LLM providers; JSON schema validation.\\n- Memory/RAG: vector databases (FAISS, Chroma, Pinecone, Weaviate), text chunkers, retrievers.\\n- Evaluation: task suites like SWE-bench (coding), WebArena/AgentBench (web), GAIA (general grounded QA).\\n\\nChallenges and risks\\n- Reliability: long-horizon planning, tool selection, and error recovery are brittle.\\n- Hallucinations and grounding: use retrieval, tool checks, and validators.\\n- Cost/latency: frequent tool calls and planning loops can be expensive/slow; cache and batch.\\n- Safety/security: prompt injection, data exfiltration, insecure tool use; enforce least privilege, input/output filters, sandboxing, rate limits, and secret isolation.\\n- Oversight: define explicit success criteria; require human-in-the-loop for high-stakes actions.\\n- Evaluation: measure task success, cumulative reward, time-to-completion, robustness, cost.\\n\\nGood practices\\n- Constrain the action space; make tools explicit and typed.\\n- Add pre/post-conditions and schema validators for tool I/O.\\n- Use retrieval and deterministic tools to ground answers.\\n- Implement retries with backoff and critique, not infinite loops.\\n- Instrument with tracing, event logs, and cost tracking.\\n- Start with non-destructive read-only modes; graduate to write actions with approvals.\\n- Regularly red-team against prompt injection and jailbreaks.\\n\\nIn short: AI agents are autonomous, goal-driven systems that perceive, decide, and act. Modern agents often use LLMs to plan and operate tools, augmented with memory, retrieval, and guardrails. The hard parts are reliability, safety, and evaluation—scope tightly, measure, and iterate.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81037a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI agents: a concise overview\\n\\nWhat they are\\n- An AI agent is a system that perceives its environment, decides what to do, and acts to achieve goals autonomously. Unlike a simple program or chatbot that only answers prompts, an agent maintains state, can plan over multiple steps, use tools, and adapt its behavior based on feedback.\\n\\nCore loop\\n- Sense: gather observations (user input, web/data APIs, sensors).\\n- Think: update internal state, reason/plan, choose an action.\\n- Act: call tools/APIs, take real-world actions, or reply.\\n- Learn: update models, memories, or policies from outcomes.\\n\\nKey components\\n- Perception: parsers, extractors, retrieval (RAG), sensors.\\n- State/memory: short-term scratchpad; longer-term episodic/semantic memory (often vector stores).\\n- Policy/reasoner: rules, planners, learned policies, or LLMs.\\n- Tools/actuators: function calls, databases, web browsers, code interpreters, robots.\\n- Planner/executor: breaks goals into steps; monitors progress; handles errors and retries.\\n- Critic/guardrails: validators, safety checks, permissioning.\\n- Reward/feedback: metrics or rewards for learning or self-correction.\\n\\nAgent types (classic to modern)\\n- Reactive: map observations directly to actions; fast, no internal model.\\n- Model-based: maintain an internal state/world model to plan.\\n- Goal/utility-based: select actions to maximize goal attainment or utility.\\n- Learning agents: improve over time via supervised, RL, or self-play.\\n- LLM-based agents: use a large language model as the “brain” for planning, tool use, and dialogue; often follow patterns like ReAct (reason + act), tool calling, and planning/critique loops.\\n- Multi-agent systems: multiple specialized agents coordinating or competing to solve complex tasks.\\n\\nCommon patterns in LLM agents\\n- Tool use: the model decides when to call functions/APIs (search, DB query, code exec).\\n- Retrieval-augmented generation: fetch relevant knowledge to ground responses.\\n- Planning and execution: decompose tasks, schedule steps, track state.\\n- Reflection/critique: review outputs, detect errors, retry with improvements.\\n- Memory: store facts, preferences, and past interactions to personalize and improve.\\n\\nUse cases\\n- Productivity: personal assistants, meeting copilots, email/calendar automation.\\n- Data/knowledge work: research, analytics, report generation, BI queries.\\n- Software: coding agents (issue triage, PRs), test generation, CI/CD ops.\\n- Operations: workflow automation across SaaS, RPA-like actions.\\n- Web agents: browsing, form-filling, procurement, competitive intel.\\n- Finance/trading: monitoring, signal extraction, execution (with strict controls).\\n- Customer support: triage, resolution with tool access and knowledge bases.\\n- Robotics/IoT: navigation, manipulation, process control.\\n\\nHow they differ from chatbots and workflows\\n- Chatbots: primarily single-turn or short multi-turn text responses; no or minimal tool use/state.\\n- Workflows/RPA: fixed sequences; brittle to change.\\n- Agents: goal-directed, stateful, can plan, choose tools, and adapt to changing conditions.\\n\\nBuilding one (practical steps)\\n- Define the goal, environment, and allowed actions/tools; restrict permissions.\\n- Choose the core reasoner: rules, planner, RL policy, or an LLM.\\n- Add perception and retrieval to ground decisions.\\n- Implement a planner/executor with error handling and retries.\\n- Add memory appropriately (start simple; avoid uncontrolled growth).\\n- Wrap tools with schemas, validation, and sandboxing.\\n- Log everything; add metrics, tracing, and evaluation harnesses.\\n- Start with a narrow scope; iterate with real tasks and feedback.\\n\\nEcosystem and frameworks (examples)\\n- Orchestration: LangChain/LangGraph, Microsoft Semantic Kernel, AutoGen, CrewAI.\\n- Tool-calling: function/tool APIs from major LLM providers; JSON schema validation.\\n- Memory/RAG: vector databases (FAISS, Chroma, Pinecone, Weaviate), text chunkers, retrievers.\\n- Evaluation: task suites like SWE-bench (coding), WebArena/AgentBench (web), GAIA (general grounded QA).\\n\\nChallenges and risks\\n- Reliability: long-horizon planning, tool selection, and error recovery are brittle.\\n- Hallucinations and grounding: use retrieval, tool checks, and validators.\\n- Cost/latency: frequent tool calls and planning loops can be expensive/slow; cache and batch.\\n- Safety/security: prompt injection, data exfiltration, insecure tool use; enforce least privilege, input/output filters, sandboxing, rate limits, and secret isolation.\\n- Oversight: define explicit success criteria; require human-in-the-loop for high-stakes actions.\\n- Evaluation: measure task success, cumulative reward, time-to-completion, robustness, cost.\\n\\nGood practices\\n- Constrain the action space; make tools explicit and typed.\\n- Add pre/post-conditions and schema validators for tool I/O.\\n- Use retrieval and deterministic tools to ground answers.\\n- Implement retries with backoff and critique, not infinite loops.\\n- Instrument with tracing, event logs, and cost tracking.\\n- Start with non-destructive read-only modes; graduate to write actions with approvals.\\n- Regularly red-team against prompt injection and jailbreaks.\\n\\nIn short: AI agents are autonomous, goal-driven systems that perceive, decide, and act. Modern agents often use LLMs to plan and operate tools, augmented with memory, retrieval, and guardrails. The hard parts are reliability, safety, and evaluation—scope tightly, measure, and iterate.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b781c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agents: a concise overview\n",
      "\n",
      "What they are\n",
      "- An AI agent is a system that perceives its environment, decides what to do, and acts to achieve goals autonomously. Unlike a simple program or chatbot that only answers prompts, an agent maintains state, can plan over multiple steps, use tools, and adapt its behavior based on feedback.\n",
      "\n",
      "Core loop\n",
      "- Sense: gather observations (user input, web/data APIs, sensors).\n",
      "- Think: update internal state, reason/plan, choose an action.\n",
      "- Act: call tools/APIs, take real-world actions, or reply.\n",
      "- Learn: update models, memories, or policies from outcomes.\n",
      "\n",
      "Key components\n",
      "- Perception: parsers, extractors, retrieval (RAG), sensors.\n",
      "- State/memory: short-term scratchpad; longer-term episodic/semantic memory (often vector stores).\n",
      "- Policy/reasoner: rules, planners, learned policies, or LLMs.\n",
      "- Tools/actuators: function calls, databases, web browsers, code interpreters, robots.\n",
      "- Planner/executor: breaks goals into steps; monitors progress; handles errors and retries.\n",
      "- Critic/guardrails: validators, safety checks, permissioning.\n",
      "- Reward/feedback: metrics or rewards for learning or self-correction.\n",
      "\n",
      "Agent types (classic to modern)\n",
      "- Reactive: map observations directly to actions; fast, no internal model.\n",
      "- Model-based: maintain an internal state/world model to plan.\n",
      "- Goal/utility-based: select actions to maximize goal attainment or utility.\n",
      "- Learning agents: improve over time via supervised, RL, or self-play.\n",
      "- LLM-based agents: use a large language model as the “brain” for planning, tool use, and dialogue; often follow patterns like ReAct (reason + act), tool calling, and planning/critique loops.\n",
      "- Multi-agent systems: multiple specialized agents coordinating or competing to solve complex tasks.\n",
      "\n",
      "Common patterns in LLM agents\n",
      "- Tool use: the model decides when to call functions/APIs (search, DB query, code exec).\n",
      "- Retrieval-augmented generation: fetch relevant knowledge to ground responses.\n",
      "- Planning and execution: decompose tasks, schedule steps, track state.\n",
      "- Reflection/critique: review outputs, detect errors, retry with improvements.\n",
      "- Memory: store facts, preferences, and past interactions to personalize and improve.\n",
      "\n",
      "Use cases\n",
      "- Productivity: personal assistants, meeting copilots, email/calendar automation.\n",
      "- Data/knowledge work: research, analytics, report generation, BI queries.\n",
      "- Software: coding agents (issue triage, PRs), test generation, CI/CD ops.\n",
      "- Operations: workflow automation across SaaS, RPA-like actions.\n",
      "- Web agents: browsing, form-filling, procurement, competitive intel.\n",
      "- Finance/trading: monitoring, signal extraction, execution (with strict controls).\n",
      "- Customer support: triage, resolution with tool access and knowledge bases.\n",
      "- Robotics/IoT: navigation, manipulation, process control.\n",
      "\n",
      "How they differ from chatbots and workflows\n",
      "- Chatbots: primarily single-turn or short multi-turn text responses; no or minimal tool use/state.\n",
      "- Workflows/RPA: fixed sequences; brittle to change.\n",
      "- Agents: goal-directed, stateful, can plan, choose tools, and adapt to changing conditions.\n",
      "\n",
      "Building one (practical steps)\n",
      "- Define the goal, environment, and allowed actions/tools; restrict permissions.\n",
      "- Choose the core reasoner: rules, planner, RL policy, or an LLM.\n",
      "- Add perception and retrieval to ground decisions.\n",
      "- Implement a planner/executor with error handling and retries.\n",
      "- Add memory appropriately (start simple; avoid uncontrolled growth).\n",
      "- Wrap tools with schemas, validation, and sandboxing.\n",
      "- Log everything; add metrics, tracing, and evaluation harnesses.\n",
      "- Start with a narrow scope; iterate with real tasks and feedback.\n",
      "\n",
      "Ecosystem and frameworks (examples)\n",
      "- Orchestration: LangChain/LangGraph, Microsoft Semantic Kernel, AutoGen, CrewAI.\n",
      "- Tool-calling: function/tool APIs from major LLM providers; JSON schema validation.\n",
      "- Memory/RAG: vector databases (FAISS, Chroma, Pinecone, Weaviate), text chunkers, retrievers.\n",
      "- Evaluation: task suites like SWE-bench (coding), WebArena/AgentBench (web), GAIA (general grounded QA).\n",
      "\n",
      "Challenges and risks\n",
      "- Reliability: long-horizon planning, tool selection, and error recovery are brittle.\n",
      "- Hallucinations and grounding: use retrieval, tool checks, and validators.\n",
      "- Cost/latency: frequent tool calls and planning loops can be expensive/slow; cache and batch.\n",
      "- Safety/security: prompt injection, data exfiltration, insecure tool use; enforce least privilege, input/output filters, sandboxing, rate limits, and secret isolation.\n",
      "- Oversight: define explicit success criteria; require human-in-the-loop for high-stakes actions.\n",
      "- Evaluation: measure task success, cumulative reward, time-to-completion, robustness, cost.\n",
      "\n",
      "Good practices\n",
      "- Constrain the action space; make tools explicit and typed.\n",
      "- Add pre/post-conditions and schema validators for tool I/O.\n",
      "- Use retrieval and deterministic tools to ground answers.\n",
      "- Implement retries with backoff and critique, not infinite loops.\n",
      "- Instrument with tracing, event logs, and cost tracking.\n",
      "- Start with non-destructive read-only modes; graduate to write actions with approvals.\n",
      "- Regularly red-team against prompt injection and jailbreaks.\n",
      "\n",
      "In short: AI agents are autonomous, goal-driven systems that perceive, decide, and act. Modern agents often use LLMs to plan and operate tools, augmented with memory, retrieval, and guardrails. The hard parts are reliability, safety, and evaluation—scope tightly, measure, and iterate.\n"
     ]
    }
   ],
   "source": [
    "print(result_content[-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
