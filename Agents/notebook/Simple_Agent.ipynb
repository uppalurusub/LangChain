{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62550d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\"gpt-5\")\n",
    "\n",
    "#agent = create_agent(\"gpt-5\", tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931ca49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\"gpt-5\")\n",
    "\n",
    "#agent = create_agent(\"gpt-5\", tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0cec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain about AI Agents.\"}],\n",
    "    \"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22cfae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain about AI Agents.', additional_kwargs={}, response_metadata={}, id='d71f6287-59f0-45ea-be14-637de299586f'),\n",
       "  AIMessage(content='AI agents are software systems that can perceive their environment, decide what to do, and act toward a goal—often using large language models (LLMs) for reasoning and tool use. They differ from static programs by running a sense–think–act loop, adapting to feedback instead of following a fixed script.\\n\\nCore loop and components\\n- Perception: Read inputs (user requests, files, APIs, sensors).\\n- Reasoning/Planning: Decide on a plan from goals and context (often via an LLM).\\n- Tool use: Call functions, APIs, databases, code interpreters, browsers, or robots.\\n- Memory: Keep short-term state for the current task and long-term knowledge for reuse.\\n- Action: Execute steps, observe results, and iterate until done or a stop condition.\\n- Oversight: Guardrails, permissions, human approvals, and logging.\\n\\nLevels and types\\n- Assistive (co-pilots): Suggest actions; a human clicks “run.” Best for safety-critical or costly tasks.\\n- Semi-autonomous: Execute within predefined boundaries (budgets, allow-listed tools); escalate for approval.\\n- Autonomous: Pursue goals continuously with minimal supervision; used in simulations, back-office ops, or research.\\n- Single-agent vs multi-agent: One generalist vs specialized agents that collaborate (e.g., planner + executors).\\n\\nCommon capabilities\\n- Retrieval and knowledge grounding (RAG) from documents/KBs.\\n- Web browsing and data extraction.\\n- Structured tool/function calling and API orchestration.\\n- Code generation and execution in sandboxes.\\n- Workflow automation: tickets, email, CRM, spreadsheets.\\n- Data analysis, charting, and report generation.\\n- Monitoring and alert response (ops, security).\\n- Embodied action (robotics, RPA) in constrained settings.\\n\\nArchitectures and patterns\\n- ReAct: Interleave reasoning with tool calls step by step.\\n- Planner–executor: One agent makes plans; one or more execute them.\\n- Hierarchical agents: High-level goals broken into subgoals for specialists.\\n- State machines/graphs: Constrain agent flow with deterministic transitions.\\n- Toolformer/function-calling: Models choose functions with structured arguments.\\n- Multi-agent “societies”: Agents debate, critique, or vote to improve reliability.\\n\\nHow they differ from chatbots and traditional automation\\n- Chatbots respond in text; agents also take actions in tools and environments.\\n- Traditional automation is brittle but predictable; agents are adaptive but probabilistic.\\n- Agents can generalize across tasks using the same toolset and goals.\\n\\nStrengths\\n- Flexible problem solving across unfamiliar tasks.\\n- Rapid integration across tools without bespoke glue code for each path.\\n- Natural-language interfaces reduce skill barriers.\\n\\nLimitations and risks\\n- Reliability: May hallucinate, over-plan, or miss edge cases, especially in long-horizon tasks.\\n- Cost/latency: Tool calls and multi-step loops can be slow and expensive.\\n- Safety/security: Tool misuse, data leakage, prompt injection from untrusted content.\\n- Evaluation: Harder than static software; stochastic outputs and nondeterminism.\\n\\nDesigning and building an agent (practical steps)\\n- Define the goal, success metrics, and boundaries (what it’s allowed to do, budgets).\\n- Choose the model (LLM) and context sources (RAG, APIs).\\n- Define tools with strict schemas, validations, and permissions.\\n- Set up memory: working memory for the task; long-term vector or structured memory if needed.\\n- Plan the control flow: fully open loop vs a constrained state machine or planner–executor.\\n- Add guardrails: allow-lists, rate limits, sandboxing, role-based access, and red-teaming.\\n- Human-in-the-loop: approvals for sensitive actions and clear fallbacks.\\n- Observability: logs, traces of tool calls, cost/latency monitoring.\\n- Evaluation: task success rate, tool-call accuracy, safety checks, regression tests with scenarios.\\n- Deployment: chat UI, API endpoint, scheduled/triggered workflows; secrets management and audits.\\n\\nWhen to use agents\\n- High-variety tasks that change often (research, ops runbooks, sales ops).\\n- Work that benefits from incremental planning and cross-tool orchestration.\\n- Situations where suggestions with human approval are acceptable.\\n\\nWhen not to use\\n- Safety-critical, regulatory tasks needing formal guarantees.\\n- Simple, repetitive workflows better covered by deterministic automation.\\n- Use cases where low latency with high predictability is mandatory.\\n\\nExamples\\n- Customer support triage agent: Classifies tickets, drafts replies, pulls account data, proposes next actions for agent approval.\\n- Data research agent: Browses the web, extracts facts, cites sources, compiles a brief with charts.\\n- DevOps on-call agent: Reads alerts, checks dashboards, runs safe diagnostics, suggests remediations, opens/updates tickets.\\n\\nEcosystem (representative, not exhaustive)\\n- Frameworks/orchestration: LangChain/LangGraph, LlamaIndex, Haystack Agents, AutoGen, CrewAI.\\n- Platform features: Function calling and tool use in major LLM APIs; “Assistants” style APIs with code interpreters, file search, and tool plugins.\\n\\nMeasuring success\\n- Task completion rate and quality (human ratings or rubrics).\\n- Number and accuracy of tool calls; error recovery success.\\n- Time/cost to completion; human effort saved.\\n- Safety incidents and permission denials.\\n- Robustness across a curated benchmark suite.\\n\\nBottom line\\nAI agents bring adaptive, goal-driven automation to software. They are powerful for orchestrating tools and information but require careful scoping, guardrails, and evaluation to be reliable in production. Start with assistive patterns, measure outcomes, and increase autonomy where the data shows it’s safe and valuable.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2078, 'prompt_tokens': 11, 'total_tokens': 2089, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ct5CazWGUQgR7kJsbKlPXzvddMurh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b77f4-8338-7f62-a4f7-379f5b9c5a17-0', usage_metadata={'input_tokens': 11, 'output_tokens': 2078, 'total_tokens': 2089, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa7e335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_content = result[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f524f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Explain about AI Agents.', additional_kwargs={}, response_metadata={}, id='d71f6287-59f0-45ea-be14-637de299586f'),\n",
       " AIMessage(content='AI agents are software systems that can perceive their environment, decide what to do, and act toward a goal—often using large language models (LLMs) for reasoning and tool use. They differ from static programs by running a sense–think–act loop, adapting to feedback instead of following a fixed script.\\n\\nCore loop and components\\n- Perception: Read inputs (user requests, files, APIs, sensors).\\n- Reasoning/Planning: Decide on a plan from goals and context (often via an LLM).\\n- Tool use: Call functions, APIs, databases, code interpreters, browsers, or robots.\\n- Memory: Keep short-term state for the current task and long-term knowledge for reuse.\\n- Action: Execute steps, observe results, and iterate until done or a stop condition.\\n- Oversight: Guardrails, permissions, human approvals, and logging.\\n\\nLevels and types\\n- Assistive (co-pilots): Suggest actions; a human clicks “run.” Best for safety-critical or costly tasks.\\n- Semi-autonomous: Execute within predefined boundaries (budgets, allow-listed tools); escalate for approval.\\n- Autonomous: Pursue goals continuously with minimal supervision; used in simulations, back-office ops, or research.\\n- Single-agent vs multi-agent: One generalist vs specialized agents that collaborate (e.g., planner + executors).\\n\\nCommon capabilities\\n- Retrieval and knowledge grounding (RAG) from documents/KBs.\\n- Web browsing and data extraction.\\n- Structured tool/function calling and API orchestration.\\n- Code generation and execution in sandboxes.\\n- Workflow automation: tickets, email, CRM, spreadsheets.\\n- Data analysis, charting, and report generation.\\n- Monitoring and alert response (ops, security).\\n- Embodied action (robotics, RPA) in constrained settings.\\n\\nArchitectures and patterns\\n- ReAct: Interleave reasoning with tool calls step by step.\\n- Planner–executor: One agent makes plans; one or more execute them.\\n- Hierarchical agents: High-level goals broken into subgoals for specialists.\\n- State machines/graphs: Constrain agent flow with deterministic transitions.\\n- Toolformer/function-calling: Models choose functions with structured arguments.\\n- Multi-agent “societies”: Agents debate, critique, or vote to improve reliability.\\n\\nHow they differ from chatbots and traditional automation\\n- Chatbots respond in text; agents also take actions in tools and environments.\\n- Traditional automation is brittle but predictable; agents are adaptive but probabilistic.\\n- Agents can generalize across tasks using the same toolset and goals.\\n\\nStrengths\\n- Flexible problem solving across unfamiliar tasks.\\n- Rapid integration across tools without bespoke glue code for each path.\\n- Natural-language interfaces reduce skill barriers.\\n\\nLimitations and risks\\n- Reliability: May hallucinate, over-plan, or miss edge cases, especially in long-horizon tasks.\\n- Cost/latency: Tool calls and multi-step loops can be slow and expensive.\\n- Safety/security: Tool misuse, data leakage, prompt injection from untrusted content.\\n- Evaluation: Harder than static software; stochastic outputs and nondeterminism.\\n\\nDesigning and building an agent (practical steps)\\n- Define the goal, success metrics, and boundaries (what it’s allowed to do, budgets).\\n- Choose the model (LLM) and context sources (RAG, APIs).\\n- Define tools with strict schemas, validations, and permissions.\\n- Set up memory: working memory for the task; long-term vector or structured memory if needed.\\n- Plan the control flow: fully open loop vs a constrained state machine or planner–executor.\\n- Add guardrails: allow-lists, rate limits, sandboxing, role-based access, and red-teaming.\\n- Human-in-the-loop: approvals for sensitive actions and clear fallbacks.\\n- Observability: logs, traces of tool calls, cost/latency monitoring.\\n- Evaluation: task success rate, tool-call accuracy, safety checks, regression tests with scenarios.\\n- Deployment: chat UI, API endpoint, scheduled/triggered workflows; secrets management and audits.\\n\\nWhen to use agents\\n- High-variety tasks that change often (research, ops runbooks, sales ops).\\n- Work that benefits from incremental planning and cross-tool orchestration.\\n- Situations where suggestions with human approval are acceptable.\\n\\nWhen not to use\\n- Safety-critical, regulatory tasks needing formal guarantees.\\n- Simple, repetitive workflows better covered by deterministic automation.\\n- Use cases where low latency with high predictability is mandatory.\\n\\nExamples\\n- Customer support triage agent: Classifies tickets, drafts replies, pulls account data, proposes next actions for agent approval.\\n- Data research agent: Browses the web, extracts facts, cites sources, compiles a brief with charts.\\n- DevOps on-call agent: Reads alerts, checks dashboards, runs safe diagnostics, suggests remediations, opens/updates tickets.\\n\\nEcosystem (representative, not exhaustive)\\n- Frameworks/orchestration: LangChain/LangGraph, LlamaIndex, Haystack Agents, AutoGen, CrewAI.\\n- Platform features: Function calling and tool use in major LLM APIs; “Assistants” style APIs with code interpreters, file search, and tool plugins.\\n\\nMeasuring success\\n- Task completion rate and quality (human ratings or rubrics).\\n- Number and accuracy of tool calls; error recovery success.\\n- Time/cost to completion; human effort saved.\\n- Safety incidents and permission denials.\\n- Robustness across a curated benchmark suite.\\n\\nBottom line\\nAI agents bring adaptive, goal-driven automation to software. They are powerful for orchestrating tools and information but require careful scoping, guardrails, and evaluation to be reliable in production. Start with assistive patterns, measure outcomes, and increase autonomy where the data shows it’s safe and valuable.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2078, 'prompt_tokens': 11, 'total_tokens': 2089, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ct5CazWGUQgR7kJsbKlPXzvddMurh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b77f4-8338-7f62-a4f7-379f5b9c5a17-0', usage_metadata={'input_tokens': 11, 'output_tokens': 2078, 'total_tokens': 2089, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bd6642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c31036f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='Explain about AI Agents.', additional_kwargs={}, response_metadata={}, id='d71f6287-59f0-45ea-be14-637de299586f')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69acde87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain about AI Agents.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a62bc940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI agents are software systems that can perceive their environment, decide what to do, and act toward a goal—often using large language models (LLMs) for reasoning and tool use. They differ from static programs by running a sense–think–act loop, adapting to feedback instead of following a fixed script.\\n\\nCore loop and components\\n- Perception: Read inputs (user requests, files, APIs, sensors).\\n- Reasoning/Planning: Decide on a plan from goals and context (often via an LLM).\\n- Tool use: Call functions, APIs, databases, code interpreters, browsers, or robots.\\n- Memory: Keep short-term state for the current task and long-term knowledge for reuse.\\n- Action: Execute steps, observe results, and iterate until done or a stop condition.\\n- Oversight: Guardrails, permissions, human approvals, and logging.\\n\\nLevels and types\\n- Assistive (co-pilots): Suggest actions; a human clicks “run.” Best for safety-critical or costly tasks.\\n- Semi-autonomous: Execute within predefined boundaries (budgets, allow-listed tools); escalate for approval.\\n- Autonomous: Pursue goals continuously with minimal supervision; used in simulations, back-office ops, or research.\\n- Single-agent vs multi-agent: One generalist vs specialized agents that collaborate (e.g., planner + executors).\\n\\nCommon capabilities\\n- Retrieval and knowledge grounding (RAG) from documents/KBs.\\n- Web browsing and data extraction.\\n- Structured tool/function calling and API orchestration.\\n- Code generation and execution in sandboxes.\\n- Workflow automation: tickets, email, CRM, spreadsheets.\\n- Data analysis, charting, and report generation.\\n- Monitoring and alert response (ops, security).\\n- Embodied action (robotics, RPA) in constrained settings.\\n\\nArchitectures and patterns\\n- ReAct: Interleave reasoning with tool calls step by step.\\n- Planner–executor: One agent makes plans; one or more execute them.\\n- Hierarchical agents: High-level goals broken into subgoals for specialists.\\n- State machines/graphs: Constrain agent flow with deterministic transitions.\\n- Toolformer/function-calling: Models choose functions with structured arguments.\\n- Multi-agent “societies”: Agents debate, critique, or vote to improve reliability.\\n\\nHow they differ from chatbots and traditional automation\\n- Chatbots respond in text; agents also take actions in tools and environments.\\n- Traditional automation is brittle but predictable; agents are adaptive but probabilistic.\\n- Agents can generalize across tasks using the same toolset and goals.\\n\\nStrengths\\n- Flexible problem solving across unfamiliar tasks.\\n- Rapid integration across tools without bespoke glue code for each path.\\n- Natural-language interfaces reduce skill barriers.\\n\\nLimitations and risks\\n- Reliability: May hallucinate, over-plan, or miss edge cases, especially in long-horizon tasks.\\n- Cost/latency: Tool calls and multi-step loops can be slow and expensive.\\n- Safety/security: Tool misuse, data leakage, prompt injection from untrusted content.\\n- Evaluation: Harder than static software; stochastic outputs and nondeterminism.\\n\\nDesigning and building an agent (practical steps)\\n- Define the goal, success metrics, and boundaries (what it’s allowed to do, budgets).\\n- Choose the model (LLM) and context sources (RAG, APIs).\\n- Define tools with strict schemas, validations, and permissions.\\n- Set up memory: working memory for the task; long-term vector or structured memory if needed.\\n- Plan the control flow: fully open loop vs a constrained state machine or planner–executor.\\n- Add guardrails: allow-lists, rate limits, sandboxing, role-based access, and red-teaming.\\n- Human-in-the-loop: approvals for sensitive actions and clear fallbacks.\\n- Observability: logs, traces of tool calls, cost/latency monitoring.\\n- Evaluation: task success rate, tool-call accuracy, safety checks, regression tests with scenarios.\\n- Deployment: chat UI, API endpoint, scheduled/triggered workflows; secrets management and audits.\\n\\nWhen to use agents\\n- High-variety tasks that change often (research, ops runbooks, sales ops).\\n- Work that benefits from incremental planning and cross-tool orchestration.\\n- Situations where suggestions with human approval are acceptable.\\n\\nWhen not to use\\n- Safety-critical, regulatory tasks needing formal guarantees.\\n- Simple, repetitive workflows better covered by deterministic automation.\\n- Use cases where low latency with high predictability is mandatory.\\n\\nExamples\\n- Customer support triage agent: Classifies tickets, drafts replies, pulls account data, proposes next actions for agent approval.\\n- Data research agent: Browses the web, extracts facts, cites sources, compiles a brief with charts.\\n- DevOps on-call agent: Reads alerts, checks dashboards, runs safe diagnostics, suggests remediations, opens/updates tickets.\\n\\nEcosystem (representative, not exhaustive)\\n- Frameworks/orchestration: LangChain/LangGraph, LlamaIndex, Haystack Agents, AutoGen, CrewAI.\\n- Platform features: Function calling and tool use in major LLM APIs; “Assistants” style APIs with code interpreters, file search, and tool plugins.\\n\\nMeasuring success\\n- Task completion rate and quality (human ratings or rubrics).\\n- Number and accuracy of tool calls; error recovery success.\\n- Time/cost to completion; human effort saved.\\n- Safety incidents and permission denials.\\n- Robustness across a curated benchmark suite.\\n\\nBottom line\\nAI agents bring adaptive, goal-driven automation to software. They are powerful for orchestrating tools and information but require careful scoping, guardrails, and evaluation to be reliable in production. Start with assistive patterns, measure outcomes, and increase autonomy where the data shows it’s safe and valuable.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2078, 'prompt_tokens': 11, 'total_tokens': 2089, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ct5CazWGUQgR7kJsbKlPXzvddMurh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b77f4-8338-7f62-a4f7-379f5b9c5a17-0', usage_metadata={'input_tokens': 11, 'output_tokens': 2078, 'total_tokens': 2089, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3ea03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI agents are software systems that can perceive their environment, decide what to do, and act toward a goal—often using large language models (LLMs) for reasoning and tool use. They differ from static programs by running a sense–think–act loop, adapting to feedback instead of following a fixed script.\\n\\nCore loop and components\\n- Perception: Read inputs (user requests, files, APIs, sensors).\\n- Reasoning/Planning: Decide on a plan from goals and context (often via an LLM).\\n- Tool use: Call functions, APIs, databases, code interpreters, browsers, or robots.\\n- Memory: Keep short-term state for the current task and long-term knowledge for reuse.\\n- Action: Execute steps, observe results, and iterate until done or a stop condition.\\n- Oversight: Guardrails, permissions, human approvals, and logging.\\n\\nLevels and types\\n- Assistive (co-pilots): Suggest actions; a human clicks “run.” Best for safety-critical or costly tasks.\\n- Semi-autonomous: Execute within predefined boundaries (budgets, allow-listed tools); escalate for approval.\\n- Autonomous: Pursue goals continuously with minimal supervision; used in simulations, back-office ops, or research.\\n- Single-agent vs multi-agent: One generalist vs specialized agents that collaborate (e.g., planner + executors).\\n\\nCommon capabilities\\n- Retrieval and knowledge grounding (RAG) from documents/KBs.\\n- Web browsing and data extraction.\\n- Structured tool/function calling and API orchestration.\\n- Code generation and execution in sandboxes.\\n- Workflow automation: tickets, email, CRM, spreadsheets.\\n- Data analysis, charting, and report generation.\\n- Monitoring and alert response (ops, security).\\n- Embodied action (robotics, RPA) in constrained settings.\\n\\nArchitectures and patterns\\n- ReAct: Interleave reasoning with tool calls step by step.\\n- Planner–executor: One agent makes plans; one or more execute them.\\n- Hierarchical agents: High-level goals broken into subgoals for specialists.\\n- State machines/graphs: Constrain agent flow with deterministic transitions.\\n- Toolformer/function-calling: Models choose functions with structured arguments.\\n- Multi-agent “societies”: Agents debate, critique, or vote to improve reliability.\\n\\nHow they differ from chatbots and traditional automation\\n- Chatbots respond in text; agents also take actions in tools and environments.\\n- Traditional automation is brittle but predictable; agents are adaptive but probabilistic.\\n- Agents can generalize across tasks using the same toolset and goals.\\n\\nStrengths\\n- Flexible problem solving across unfamiliar tasks.\\n- Rapid integration across tools without bespoke glue code for each path.\\n- Natural-language interfaces reduce skill barriers.\\n\\nLimitations and risks\\n- Reliability: May hallucinate, over-plan, or miss edge cases, especially in long-horizon tasks.\\n- Cost/latency: Tool calls and multi-step loops can be slow and expensive.\\n- Safety/security: Tool misuse, data leakage, prompt injection from untrusted content.\\n- Evaluation: Harder than static software; stochastic outputs and nondeterminism.\\n\\nDesigning and building an agent (practical steps)\\n- Define the goal, success metrics, and boundaries (what it’s allowed to do, budgets).\\n- Choose the model (LLM) and context sources (RAG, APIs).\\n- Define tools with strict schemas, validations, and permissions.\\n- Set up memory: working memory for the task; long-term vector or structured memory if needed.\\n- Plan the control flow: fully open loop vs a constrained state machine or planner–executor.\\n- Add guardrails: allow-lists, rate limits, sandboxing, role-based access, and red-teaming.\\n- Human-in-the-loop: approvals for sensitive actions and clear fallbacks.\\n- Observability: logs, traces of tool calls, cost/latency monitoring.\\n- Evaluation: task success rate, tool-call accuracy, safety checks, regression tests with scenarios.\\n- Deployment: chat UI, API endpoint, scheduled/triggered workflows; secrets management and audits.\\n\\nWhen to use agents\\n- High-variety tasks that change often (research, ops runbooks, sales ops).\\n- Work that benefits from incremental planning and cross-tool orchestration.\\n- Situations where suggestions with human approval are acceptable.\\n\\nWhen not to use\\n- Safety-critical, regulatory tasks needing formal guarantees.\\n- Simple, repetitive workflows better covered by deterministic automation.\\n- Use cases where low latency with high predictability is mandatory.\\n\\nExamples\\n- Customer support triage agent: Classifies tickets, drafts replies, pulls account data, proposes next actions for agent approval.\\n- Data research agent: Browses the web, extracts facts, cites sources, compiles a brief with charts.\\n- DevOps on-call agent: Reads alerts, checks dashboards, runs safe diagnostics, suggests remediations, opens/updates tickets.\\n\\nEcosystem (representative, not exhaustive)\\n- Frameworks/orchestration: LangChain/LangGraph, LlamaIndex, Haystack Agents, AutoGen, CrewAI.\\n- Platform features: Function calling and tool use in major LLM APIs; “Assistants” style APIs with code interpreters, file search, and tool plugins.\\n\\nMeasuring success\\n- Task completion rate and quality (human ratings or rubrics).\\n- Number and accuracy of tool calls; error recovery success.\\n- Time/cost to completion; human effort saved.\\n- Safety incidents and permission denials.\\n- Robustness across a curated benchmark suite.\\n\\nBottom line\\nAI agents bring adaptive, goal-driven automation to software. They are powerful for orchestrating tools and information but require careful scoping, guardrails, and evaluation to be reliable in production. Start with assistive patterns, measure outcomes, and increase autonomy where the data shows it’s safe and valuable.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a81037a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI agents are software systems that can perceive their environment, decide what to do, and act toward a goal—often using large language models (LLMs) for reasoning and tool use. They differ from static programs by running a sense–think–act loop, adapting to feedback instead of following a fixed script.\\n\\nCore loop and components\\n- Perception: Read inputs (user requests, files, APIs, sensors).\\n- Reasoning/Planning: Decide on a plan from goals and context (often via an LLM).\\n- Tool use: Call functions, APIs, databases, code interpreters, browsers, or robots.\\n- Memory: Keep short-term state for the current task and long-term knowledge for reuse.\\n- Action: Execute steps, observe results, and iterate until done or a stop condition.\\n- Oversight: Guardrails, permissions, human approvals, and logging.\\n\\nLevels and types\\n- Assistive (co-pilots): Suggest actions; a human clicks “run.” Best for safety-critical or costly tasks.\\n- Semi-autonomous: Execute within predefined boundaries (budgets, allow-listed tools); escalate for approval.\\n- Autonomous: Pursue goals continuously with minimal supervision; used in simulations, back-office ops, or research.\\n- Single-agent vs multi-agent: One generalist vs specialized agents that collaborate (e.g., planner + executors).\\n\\nCommon capabilities\\n- Retrieval and knowledge grounding (RAG) from documents/KBs.\\n- Web browsing and data extraction.\\n- Structured tool/function calling and API orchestration.\\n- Code generation and execution in sandboxes.\\n- Workflow automation: tickets, email, CRM, spreadsheets.\\n- Data analysis, charting, and report generation.\\n- Monitoring and alert response (ops, security).\\n- Embodied action (robotics, RPA) in constrained settings.\\n\\nArchitectures and patterns\\n- ReAct: Interleave reasoning with tool calls step by step.\\n- Planner–executor: One agent makes plans; one or more execute them.\\n- Hierarchical agents: High-level goals broken into subgoals for specialists.\\n- State machines/graphs: Constrain agent flow with deterministic transitions.\\n- Toolformer/function-calling: Models choose functions with structured arguments.\\n- Multi-agent “societies”: Agents debate, critique, or vote to improve reliability.\\n\\nHow they differ from chatbots and traditional automation\\n- Chatbots respond in text; agents also take actions in tools and environments.\\n- Traditional automation is brittle but predictable; agents are adaptive but probabilistic.\\n- Agents can generalize across tasks using the same toolset and goals.\\n\\nStrengths\\n- Flexible problem solving across unfamiliar tasks.\\n- Rapid integration across tools without bespoke glue code for each path.\\n- Natural-language interfaces reduce skill barriers.\\n\\nLimitations and risks\\n- Reliability: May hallucinate, over-plan, or miss edge cases, especially in long-horizon tasks.\\n- Cost/latency: Tool calls and multi-step loops can be slow and expensive.\\n- Safety/security: Tool misuse, data leakage, prompt injection from untrusted content.\\n- Evaluation: Harder than static software; stochastic outputs and nondeterminism.\\n\\nDesigning and building an agent (practical steps)\\n- Define the goal, success metrics, and boundaries (what it’s allowed to do, budgets).\\n- Choose the model (LLM) and context sources (RAG, APIs).\\n- Define tools with strict schemas, validations, and permissions.\\n- Set up memory: working memory for the task; long-term vector or structured memory if needed.\\n- Plan the control flow: fully open loop vs a constrained state machine or planner–executor.\\n- Add guardrails: allow-lists, rate limits, sandboxing, role-based access, and red-teaming.\\n- Human-in-the-loop: approvals for sensitive actions and clear fallbacks.\\n- Observability: logs, traces of tool calls, cost/latency monitoring.\\n- Evaluation: task success rate, tool-call accuracy, safety checks, regression tests with scenarios.\\n- Deployment: chat UI, API endpoint, scheduled/triggered workflows; secrets management and audits.\\n\\nWhen to use agents\\n- High-variety tasks that change often (research, ops runbooks, sales ops).\\n- Work that benefits from incremental planning and cross-tool orchestration.\\n- Situations where suggestions with human approval are acceptable.\\n\\nWhen not to use\\n- Safety-critical, regulatory tasks needing formal guarantees.\\n- Simple, repetitive workflows better covered by deterministic automation.\\n- Use cases where low latency with high predictability is mandatory.\\n\\nExamples\\n- Customer support triage agent: Classifies tickets, drafts replies, pulls account data, proposes next actions for agent approval.\\n- Data research agent: Browses the web, extracts facts, cites sources, compiles a brief with charts.\\n- DevOps on-call agent: Reads alerts, checks dashboards, runs safe diagnostics, suggests remediations, opens/updates tickets.\\n\\nEcosystem (representative, not exhaustive)\\n- Frameworks/orchestration: LangChain/LangGraph, LlamaIndex, Haystack Agents, AutoGen, CrewAI.\\n- Platform features: Function calling and tool use in major LLM APIs; “Assistants” style APIs with code interpreters, file search, and tool plugins.\\n\\nMeasuring success\\n- Task completion rate and quality (human ratings or rubrics).\\n- Number and accuracy of tool calls; error recovery success.\\n- Time/cost to completion; human effort saved.\\n- Safety incidents and permission denials.\\n- Robustness across a curated benchmark suite.\\n\\nBottom line\\nAI agents bring adaptive, goal-driven automation to software. They are powerful for orchestrating tools and information but require careful scoping, guardrails, and evaluation to be reliable in production. Start with assistive patterns, measure outcomes, and increase autonomy where the data shows it’s safe and valuable.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_content[-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b781c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agents are software systems that can perceive their environment, decide what to do, and act toward a goal—often using large language models (LLMs) for reasoning and tool use. They differ from static programs by running a sense–think–act loop, adapting to feedback instead of following a fixed script.\n",
      "\n",
      "Core loop and components\n",
      "- Perception: Read inputs (user requests, files, APIs, sensors).\n",
      "- Reasoning/Planning: Decide on a plan from goals and context (often via an LLM).\n",
      "- Tool use: Call functions, APIs, databases, code interpreters, browsers, or robots.\n",
      "- Memory: Keep short-term state for the current task and long-term knowledge for reuse.\n",
      "- Action: Execute steps, observe results, and iterate until done or a stop condition.\n",
      "- Oversight: Guardrails, permissions, human approvals, and logging.\n",
      "\n",
      "Levels and types\n",
      "- Assistive (co-pilots): Suggest actions; a human clicks “run.” Best for safety-critical or costly tasks.\n",
      "- Semi-autonomous: Execute within predefined boundaries (budgets, allow-listed tools); escalate for approval.\n",
      "- Autonomous: Pursue goals continuously with minimal supervision; used in simulations, back-office ops, or research.\n",
      "- Single-agent vs multi-agent: One generalist vs specialized agents that collaborate (e.g., planner + executors).\n",
      "\n",
      "Common capabilities\n",
      "- Retrieval and knowledge grounding (RAG) from documents/KBs.\n",
      "- Web browsing and data extraction.\n",
      "- Structured tool/function calling and API orchestration.\n",
      "- Code generation and execution in sandboxes.\n",
      "- Workflow automation: tickets, email, CRM, spreadsheets.\n",
      "- Data analysis, charting, and report generation.\n",
      "- Monitoring and alert response (ops, security).\n",
      "- Embodied action (robotics, RPA) in constrained settings.\n",
      "\n",
      "Architectures and patterns\n",
      "- ReAct: Interleave reasoning with tool calls step by step.\n",
      "- Planner–executor: One agent makes plans; one or more execute them.\n",
      "- Hierarchical agents: High-level goals broken into subgoals for specialists.\n",
      "- State machines/graphs: Constrain agent flow with deterministic transitions.\n",
      "- Toolformer/function-calling: Models choose functions with structured arguments.\n",
      "- Multi-agent “societies”: Agents debate, critique, or vote to improve reliability.\n",
      "\n",
      "How they differ from chatbots and traditional automation\n",
      "- Chatbots respond in text; agents also take actions in tools and environments.\n",
      "- Traditional automation is brittle but predictable; agents are adaptive but probabilistic.\n",
      "- Agents can generalize across tasks using the same toolset and goals.\n",
      "\n",
      "Strengths\n",
      "- Flexible problem solving across unfamiliar tasks.\n",
      "- Rapid integration across tools without bespoke glue code for each path.\n",
      "- Natural-language interfaces reduce skill barriers.\n",
      "\n",
      "Limitations and risks\n",
      "- Reliability: May hallucinate, over-plan, or miss edge cases, especially in long-horizon tasks.\n",
      "- Cost/latency: Tool calls and multi-step loops can be slow and expensive.\n",
      "- Safety/security: Tool misuse, data leakage, prompt injection from untrusted content.\n",
      "- Evaluation: Harder than static software; stochastic outputs and nondeterminism.\n",
      "\n",
      "Designing and building an agent (practical steps)\n",
      "- Define the goal, success metrics, and boundaries (what it’s allowed to do, budgets).\n",
      "- Choose the model (LLM) and context sources (RAG, APIs).\n",
      "- Define tools with strict schemas, validations, and permissions.\n",
      "- Set up memory: working memory for the task; long-term vector or structured memory if needed.\n",
      "- Plan the control flow: fully open loop vs a constrained state machine or planner–executor.\n",
      "- Add guardrails: allow-lists, rate limits, sandboxing, role-based access, and red-teaming.\n",
      "- Human-in-the-loop: approvals for sensitive actions and clear fallbacks.\n",
      "- Observability: logs, traces of tool calls, cost/latency monitoring.\n",
      "- Evaluation: task success rate, tool-call accuracy, safety checks, regression tests with scenarios.\n",
      "- Deployment: chat UI, API endpoint, scheduled/triggered workflows; secrets management and audits.\n",
      "\n",
      "When to use agents\n",
      "- High-variety tasks that change often (research, ops runbooks, sales ops).\n",
      "- Work that benefits from incremental planning and cross-tool orchestration.\n",
      "- Situations where suggestions with human approval are acceptable.\n",
      "\n",
      "When not to use\n",
      "- Safety-critical, regulatory tasks needing formal guarantees.\n",
      "- Simple, repetitive workflows better covered by deterministic automation.\n",
      "- Use cases where low latency with high predictability is mandatory.\n",
      "\n",
      "Examples\n",
      "- Customer support triage agent: Classifies tickets, drafts replies, pulls account data, proposes next actions for agent approval.\n",
      "- Data research agent: Browses the web, extracts facts, cites sources, compiles a brief with charts.\n",
      "- DevOps on-call agent: Reads alerts, checks dashboards, runs safe diagnostics, suggests remediations, opens/updates tickets.\n",
      "\n",
      "Ecosystem (representative, not exhaustive)\n",
      "- Frameworks/orchestration: LangChain/LangGraph, LlamaIndex, Haystack Agents, AutoGen, CrewAI.\n",
      "- Platform features: Function calling and tool use in major LLM APIs; “Assistants” style APIs with code interpreters, file search, and tool plugins.\n",
      "\n",
      "Measuring success\n",
      "- Task completion rate and quality (human ratings or rubrics).\n",
      "- Number and accuracy of tool calls; error recovery success.\n",
      "- Time/cost to completion; human effort saved.\n",
      "- Safety incidents and permission denials.\n",
      "- Robustness across a curated benchmark suite.\n",
      "\n",
      "Bottom line\n",
      "AI agents bring adaptive, goal-driven automation to software. They are powerful for orchestrating tools and information but require careful scoping, guardrails, and evaluation to be reliable in production. Start with assistive patterns, measure outcomes, and increase autonomy where the data shows it’s safe and valuable.\n"
     ]
    }
   ],
   "source": [
    "print(result_content[-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
